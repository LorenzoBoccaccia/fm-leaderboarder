{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a0e44ff-c46c-4998-88d7-fb3aee89841d",
   "metadata": {},
   "source": [
    "# Text generation models evaluation\n",
    "\n",
    "#### This notebook evaluates several LLMs from Bedrock, HuggingFace, Jumpstart, Bedrock finetuned models\n",
    "#### Instance type used for the evaluation - ml.g4dn.2xlarge or m5.2xlarge, python 3.10\n",
    "#### The metrics evaluated are N-gram matching-based (ROUGE, METEOR) and sematic-based (BERTScore) from FMEval library (can be further customized)\n",
    "#### The datasets used is TweetSumm (EMNLP 21) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68c047c8-0168-45eb-9d59-dda0117ff703",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "OUTPUT_BUCKET =  # the path to the S3 bucket where the output zip will be uploaded\n",
    "\n",
    "MODELS_TO_EVAL = [] # if empty list will evaluate all the models available. For specific models, mention their ids from the list below, for example [\"anthropic.claude-v2:1\", \"amazon.titan-text-lite-v1\"]\n",
    "\n",
    "OUTPUT_FILENAME = \"test_samples_result\" # the name of the output zip that will contain the eval results\n",
    "### Metrics to calc\n",
    "# BARTscore - for more details https://github.com/neulab/BARTScore/blob/main/README.md\n",
    "CALC_BARTSCORE = True\n",
    "PATH_TO_FINETUNED_BART = \"\" # if left empty will use vanilla BART. If you wish to load the finetuned BART, go to BARTscore's github, download the bart_score.pth (appear on the README) and provide the path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb788c86-761a-4749-927f-737c194e4613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip --quiet\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f5d06f",
   "metadata": {},
   "source": [
    "### OPEN AI API key\n",
    "This is relevant if you'll be using models from OpenAI\n",
    "\n",
    "- Create a new file called `utils/key.py` in your project directory to store your API key.\n",
    "- Do **not** commit `key.py` to source control, as it contains sensitive information. **Add `*key.py` to `.gitgnore`.** Review [this information about API safety](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety).\n",
    "- Go to your OpenAI account and navigate to \"[View API keys](https://platform.openai.com/account/api-keys).\"\n",
    "- Select \"Create new secret key.\"\n",
    "- Copy the key and insert it into your file `utils/key.py` like this:\n",
    "```\n",
    "OPENAI_API_KEY = 'sk-actualLongKeyGoesHere123'\n",
    "```\n",
    "- Save the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75cfe9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.key import OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fbff43-d21a-40c6-b430-3def8ae7c268",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define bucket config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11956018-0992-4ec5-bb51-d73b1c017988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for Salesforce/dialogstudio contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/Salesforce/dialogstudio\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size: 220\n",
      "Train set size: 879\n",
      "Created training set file that can be used for Bedrock finetuning under the folder: /tmp/dataset_files/bedrock_train_tweetsumm.jsonl\n",
      "/tmp/dataset_files/test_tweetsumm_modified.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import boto3\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "from fmeval.model_runners.bedrock_model_runner import BedrockModelRunner\n",
    "from fmeval.model_runners.sm_jumpstart_model_runner import JumpStartModelRunner\n",
    "\n",
    "from utils.model_runners.gpt_model_runner import GPTModelConfig, GPTModelRunner\n",
    "from utils.tweetsumm_data_creator import create_train_test_files\n",
    "from utils.dashboard_creators.output_viewer_creator import create_response_output_view\n",
    "from utils.dashboard_creators.comparative_dashboard_creator import create_comparive_dashboard\n",
    "from utils.dashboard_creators.data_stats_viewer_creator import create_data_stats_view\n",
    "from utils.dashboard_creators.data_preview_viewer import create_data_preview_view\n",
    "from utils.dashboard_creators.main_html_creator import create_main_html\n",
    "from utils.metrics.bart_score import calculate_bartscore\n",
    "\n",
    "RESULT_FOLDER = \"/tmp/final_result\"\n",
    "if os.path.exists(RESULT_FOLDER):\n",
    "    shutil.rmtree(RESULT_FOLDER)\n",
    "os.mkdir(RESULT_FOLDER)\n",
    "\n",
    "TMP_JSON_FILES = \"/tmp/jsonl_model_files\"\n",
    "if os.path.exists(TMP_JSON_FILES):\n",
    "    shutil.rmtree(TMP_JSON_FILES)\n",
    "os.mkdir(TMP_JSON_FILES)\n",
    "\n",
    "TMP_DATASET_FILES = \"/tmp/dataset_files\"\n",
    "if os.path.exists(TMP_DATASET_FILES):\n",
    "    shutil.rmtree(TMP_DATASET_FILES)\n",
    "os.mkdir(TMP_DATASET_FILES)\n",
    "\n",
    "RESULT_HTML_FOLDER = RESULT_FOLDER + \"/html_files\"\n",
    "if os.path.exists(RESULT_HTML_FOLDER):\n",
    "    shutil.rmtree(RESULT_HTML_FOLDER)\n",
    "os.mkdir(RESULT_HTML_FOLDER)\n",
    "\n",
    "RESULT_IMG_FOLDER = RESULT_FOLDER + \"/imgs\"\n",
    "if os.path.exists(RESULT_IMG_FOLDER):\n",
    "    shutil.rmtree(RESULT_IMG_FOLDER)\n",
    "os.mkdir(RESULT_IMG_FOLDER)\n",
    "\n",
    "TEST_FILE_PATH = create_train_test_files(TMP_DATASET_FILES) # creating train and test files \n",
    "print(TEST_FILE_PATH)\n",
    "\n",
    "os.environ[\"PARALLELIZATION_FACTOR\"] = \"1\" # will use a single workder for FMEval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a915b-4918-4bf4-994a-7cff3701ec91",
   "metadata": {},
   "source": [
    "## Load models and create ModelRunner objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c05192f6-a93c-4c76-bb2b-d88e7205426f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bedrock models\n",
    "\n",
    "models_dict = {\n",
    "    \"random\" : { \n",
    "        \"model_id\" : \"amazon.titan-text-lite-v1\", \n",
    "        \"platform\" : \"bedrock\",\n",
    "        \"output\" : \"results[0].outputText\", \n",
    "        \"content_template\" : \"{\\\"inputText\\\": $prompt, \\\"textGenerationConfig\\\":  {\\\"maxTokenCount\\\": 100, \\\"stopSequences\\\": [], \\\"temperature\\\": 1.0, \\\"topP\\\": 1.0}}\",\n",
    "        \"prompt_template\" : \"Please ignore the following blob of text and create an unrelated text of around 2 sentences\\n $feature\\n\"\n",
    "    },\n",
    "    \"anthropic.claude-v2:1\" : { \n",
    "        \"model_id\" : \"anthropic.claude-v2:1\", \n",
    "        \"platform\" : \"bedrock\",\n",
    "        \"output\" : \"completion\", \n",
    "        \"content_template\" : \"{\\\"prompt\\\": $prompt, \\\"max_tokens_to_sample\\\": 100}\",\n",
    "        \"prompt_template\" : \"Human: Belowasd is a dialog between a customer and an agent. Please provide a short and concise summary of the conversation. The summary should be short and include a single sentence describing the customer's complaint or request, and single sentence of the agent's response or action. Please write the summary in a human readable format. Specify important and relevant amounts, dates and locations inside the summary.\\nHere is the dialog: $feature\\n\\nAssistant:\"\n",
    "    },\n",
    "    \"anthropic.claude-v2\" : { \n",
    "        \"model_id\" : \"anthropic.claude-v2\", \n",
    "        \"platform\" : \"bedrock\",\n",
    "        \"output\" : \"completion\", \n",
    "        \"content_template\" : \"{\\\"prompt\\\": $prompt, \\\"max_tokens_to_sample\\\": 100}\",\n",
    "        \"prompt_template\" : \"Human: Below is a dialog between a customer and an agent. Please provide a short and concise summary of the conversation. The summary should be short and include a single sentence describing the customer's complaint or request, and single sentence of the agent's response or action. Please write the summary in a human readable format. Specify important and relevant amounts, dates and locations inside the summary.\\nHere is the dialog: $feature\\n\\nAssistant:\"\n",
    "    },\n",
    "    \"anthropic.claude-instant-v1\" : { \n",
    "        \"model_id\" : \"anthropic.claude-instant-v1\", \n",
    "        \"platform\" : \"bedrock\",\n",
    "        \"output\" : \"completion\", \n",
    "        \"content_template\" : \"{\\\"prompt\\\": $prompt, \\\"max_tokens_to_sample\\\": 100}\",\n",
    "        \"prompt_template\" : \"Human: Below is a dialog between a customer and an agent. Please provide a short and concise summary of the conversation. The summary should be short and include a single sentence describing the customer's complaint or request, and single sentence of the agent's response or action. Please write the summary in a human readable format. Start you answer directly with the summary without any additional prefix.\\n Specify important and relevant amounts, dates and locations inside the summary. Here is the dialog: $feature\\n\\nAssistant:\"\n",
    "    },\n",
    "    \"amazon.titan-text-lite-v1\" : { \n",
    "        \"model_id\" : \"amazon.titan-text-lite-v1\", \n",
    "        \"platform\" : \"bedrock\",\n",
    "        \"output\" : \"results[0].outputText\", \n",
    "        \"content_template\" : \"{\\\"inputText\\\": $prompt, \\\"textGenerationConfig\\\":  {\\\"maxTokenCount\\\": 100, \\\"stopSequences\\\": [], \\\"temperature\\\": 1.0, \\\"topP\\\": 1.0}}\",\n",
    "        \"prompt_template\" : \"Please provide a short and concise summary of the conversation below. The summary should be short and include a single sentence describing the customer's complaint or request, and single sentence of the agent's response or action. Do not include any additional information that does not appear in the dialog.  Specify important and relevant amounts, dates and locations inside the sentences of the summary. Here is the dialog:\\n$feature\\n\\nsummary:\\n\"\n",
    "    },\n",
    "    \"amazon.titan-text-express-v1\" :{ \n",
    "        \"model_id\" : \"amazon.titan-text-express-v1\", \n",
    "        \"platform\" : \"bedrock\",\n",
    "        \"output\" : \"results[0].outputText\", \n",
    "        \"content_template\" : \"{\\\"inputText\\\": $prompt, \\\"textGenerationConfig\\\": {\\\"maxTokenCount\\\": 100, \\\"stopSequences\\\": [], \\\"temperature\\\": 1.0, \\\"topP\\\": 1.0}}\",\n",
    "        \"prompt_template\" : \"Please provide a short and concise summary of the conversation below that includes a summary of both the user and the agent.  Specify important and relevant amounts, dates and locations inside the sentences of the summary. Here is the dialog:\\n $feature\\n\\nsummary:\\n\"\n",
    "    },\n",
    "    \"amazon.titan-text-lite-v1-one-shot\" : { \n",
    "        \"model_id\" : \"amazon.titan-text-lite-v1\", \n",
    "        \"platform\" : \"bedrock\",\n",
    "        \"output\" : \"results[0].outputText\", \n",
    "        \"content_template\" : \"{\\\"inputText\\\": $prompt, \\\"textGenerationConfig\\\":  {\\\"maxTokenCount\\\": 100, \\\"stopSequences\\\": [], \\\"temperature\\\": 1.0, \\\"topP\\\": 1.0}}\",\n",
    "        \"prompt_template\" : \"[INST]Please provide a short and concise summary of the conversation below that includes a summary of both the user and the agent.  Specify important and relevant amounts, dates and locations inside the sentences of the summary. \\n Example Transcript:\\n user: bought a celcus tv from your Finchley store last year in December and it stopped working yesterday - can you repair it or change Your cctv recording from the date we bought it - agent: Can you confirm did you pay cash or card for the telvision? We accept credit/debit card statements as a proof of purchase. Steven user: Yes. I paid by card, I think there were other things I bought with the tv as well , but I remember the price of the television was 175 Actually, I just checked my bank statements and I bought the tv in January 2017 and not dec 2016 and paid for it by card - 175 agent: We would use the bank statements transaction ID to match our till receipts. If you return the television with your credit/debit card...1/2 ...statement our in store colleagues will advise you further. Steven 2/2 user: Great! Thank you. One last question, Ive recycled the Tvs box - is it rwqur Required** agent: As long as you've got proof of purchase you'll be fine Dimitar! Ewan.\\n Summary: Customer is asking to repair or change the television which is not working. Agent updated to return the television with their credit/debit card.\\n\\n [/INST] </s><s>[INST]\\n Transcript:\\n $feature [/INST]\\n Summary:\"\n",
    "    },\n",
    "    \"meta.llama2-13b-chat-v1-one-shot\" :{ \n",
    "        \"model_id\" : \"meta.llama2-13b-chat-v1\", \n",
    "        \"platform\" : \"bedrock\",\n",
    "        \"output\" : \"generation\", \n",
    "        \"content_template\" : \"{\\\"prompt\\\": $prompt, \\\"max_gen_len\\\": 100, \\\"top_p\\\": 1, \\\"temperature\\\": 1.0}\",\n",
    "        \"prompt_template\" : \"[INST] <<SYS>> Please provide a short and concise summary of the conversation below that includes a summary of both the user and the agent.  Specify important and relevant amounts, dates and locations inside the sentences of the summary.<</SYS> \\n Example Transcript:\\n user: bought a celcus tv from your Finchley store last year in December and it stopped working yesterday - can you repair it or change Your cctv recording from the date we bought it - agent: Can you confirm did you pay cash or card for the telvision? We accept credit/debit card statements as a proof of purchase. Steven user: Yes. I paid by card, I think there were other things I bought with the tv as well , but I remember the price of the television was 175 Actually, I just checked my bank statements and I bought the tv in January 2017 and not dec 2016 and paid for it by card - 175 agent: We would use the bank statements transaction ID to match our till receipts. If you return the television with your credit/debit card...1/2 ...statement our in store colleagues will advise you further. Steven 2/2 user: Great! Thank you. One last question, Ive recycled the Tvs box - is it rwqur Required** agent: As long as you've got proof of purchase you'll be fine Dimitar! Ewan.\\n Summary: Customer is asking to repair or change the television which is not working. Agent updated to return the television with their credit/debit card.\\n\\n [/INST] </s><s>[INST]\\n Transcript:\\n $feature [/INST] Summary:\"\n",
    "    },\n",
    "    \"cohere.command-light-text-v14-one-shot\" :{ \n",
    "        \"model_id\" : \"cohere.command-light-text-v14\", \n",
    "        \"platform\" : \"bedrock\",\n",
    "        \"output\" : \"generations[0].text\", \n",
    "        \"content_template\" : \"{\\\"prompt\\\": $prompt, \\\"max_tokens\\\": 100}\",\n",
    "        \"prompt_template\" : \"Please provide a short and concise summary of the conversation below that includes a summary of both the user and the agent.  Specify important and relevant amounts, dates and locations inside the sentences of the summary.\\n\\n Example Transcript:\\n user: bought a celcus tv from your Finchley store last year in December and it stopped working yesterday - can you repair it or change Your cctv recording from the date we bought it - agent: Can you confirm did you pay cash or card for the telvision? We accept credit/debit card statements as a proof of purchase. Steven user: Yes. I paid by card, I think there were other things I bought with the tv as well , but I remember the price of the television was 175 Actually, I just checked my bank statements and I bought the tv in January 2017 and not dec 2016 and paid for it by card - 175 agent: We would use the bank statements transaction ID to match our till receipts. If you return the television with your credit/debit card...1/2 ...statement our in store colleagues will advise you further. Steven 2/2 user: Great! Thank you. One last question, Ive recycled the Tvs box - is it rwqur Required** agent: As long as you've got proof of purchase you'll be fine Dimitar! Ewan.\\n Summary: Customer is asking to repair or change the television which is not working. Agent updated to return the television with their credit/debit card.\\n\\nTranscript:\\n $feature\\n Summary:\"\n",
    "    },\n",
    "    \"amazon.titan-text-express-v1-one-shot\" :{ \n",
    "        \"model_id\" : \"amazon.titan-text-express-v1\", \n",
    "        \"platform\" : \"bedrock\",\n",
    "        \"output\" : \"results[0].outputText\", \n",
    "        \"content_template\" : \"{\\\"inputText\\\": $prompt, \\\"textGenerationConfig\\\": {\\\"maxTokenCount\\\": 100, \\\"stopSequences\\\": [], \\\"temperature\\\": 1.0, \\\"topP\\\": 1.0}}\",\n",
    "        \"prompt_template\" : \"Please provide a short and concise summary of the conversation below that includes a summary of both the user and the agent.  Specify important and relevant amounts, dates and locations inside the sentences of the summary.\\n\\n Example Transcript:\\n user: bought a celcus tv from your Finchley store last year in December and it stopped working yesterday - can you repair it or change Your cctv recording from the date we bought it - agent: Can you confirm did you pay cash or card for the telvision? We accept credit/debit card statements as a proof of purchase. Steven user: Yes. I paid by card, I think there were other things I bought with the tv as well , but I remember the price of the television was 175 Actually, I just checked my bank statements and I bought the tv in January 2017 and not dec 2016 and paid for it by card - 175 agent: We would use the bank statements transaction ID to match our till receipts. If you return the television with your credit/debit card...1/2 ...statement our in store colleagues will advise you further. Steven 2/2 user: Great! Thank you. One last question, Ive recycled the Tvs box - is it rwqur Required** agent: As long as you've got proof of purchase you'll be fine Dimitar! Ewan.\\n Summary: Customer is asking to repair or change the television which is not working. Agent updated to return the television with their credit/debit card.\\n\\nTranscript:\\n $feature\\n Summary:\"\n",
    "    },\n",
    "    \"cohere.command-light-text-v14\" :{ \n",
    "        \"model_id\" : \"cohere.command-light-text-v14\", \n",
    "        \"platform\" : \"bedrock\",\n",
    "        \"output\" : \"generations[0].text\", \n",
    "        \"content_template\" : \"{\\\"prompt\\\": $prompt, \\\"max_tokens\\\": 100}\",\n",
    "        \"prompt_template\" : \"Please provide a short and concise summary of the conversation below that includes a summary of both the user and the agent.  Specify important and relevant amounts, dates and locations inside the sentences of the summary. Here is the dialog:\\n $feature\\n\\nsummary:\\n\"\n",
    "    },\n",
    "    \"meta.llama2-13b-chat-v1\" :{ \n",
    "        \"model_id\" : \"meta.llama2-13b-chat-v1\", \n",
    "        \"platform\" : \"bedrock\",\n",
    "        \"output\" : \"generation\", \n",
    "        \"content_template\" : \"{\\\"prompt\\\": $prompt, \\\"max_gen_len\\\": 100, \\\"top_p\\\": 1, \\\"temperature\\\": 1.0}\",\n",
    "        \"prompt_template\" : \"[INST]Please provide a short and concise summary of the conversation below that includes a summary of both the user and the agent.  Specify important and relevant amounts, dates and locations inside the sentences of the summary. Here is the dialog:[/INST]\\n Transcript\\n $feature \\n\\n Summary:\\n\"\n",
    "    },\n",
    "    \"gpt.3.5-turbu-0125\" :{ \n",
    "        \"model_id\" : \"gpt-3.5-turbo-0125\", \n",
    "        \"api_key\" : OPENAI_API_KEY,\n",
    "        \"platform\" : \"openai\",\n",
    "        \"temperature\" : 1,\n",
    "        \"top_p\" : 1,\n",
    "        \"max_tokens\" : 100,\n",
    "        \"prompt_template\" : \"Please provide a short and concise summary of the conversation below that includes a summary of both the user and the agent.  Specify important and relevant amounts, dates and locations inside the sentences of the summary.\\n Transcript:\\n $feature \\n Summary:\\n\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c9ca361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bedrock models\n",
    "\n",
    "models_dict = {\n",
    "    \"random\" : { \n",
    "        \"model_id\" : \"amazon.titan-text-lite-v1\", \n",
    "        \"platform\" : \"bedrock\",\n",
    "        \"output\" : \"results[0].outputText\", \n",
    "        \"content_template\" : \"{\\\"inputText\\\": $prompt, \\\"textGenerationConfig\\\":  {\\\"maxTokenCount\\\": 100, \\\"stopSequences\\\": [], \\\"temperature\\\": 1.0, \\\"topP\\\": 1.0}}\",\n",
    "        \"prompt_template\" : \"Please ignore the following blob of text and create an unrelated text of around 2 sentences\\n $feature\\n\"\n",
    "    },\n",
    "    \"anthropic.claude-instant-v1\" : { \n",
    "        \"model_id\" : \"anthropic.claude-instant-v1\", \n",
    "        \"platform\" : \"bedrock\",\n",
    "        \"output\" : \"completion\", \n",
    "        \"content_template\" : \"{\\\"prompt\\\": $prompt, \\\"max_tokens_to_sample\\\": 100}\",\n",
    "        \"prompt_template\" : \"Human: Below is a dialog between a customer and an agent. Please provide a short and concise summary of the conversation. The summary should be short and include a single sentence describing the customer's complaint or request, and single sentence of the agent's response or action. Please write the summary in a human readable format. Start you answer directly with the summary without any additional prefix.\\n Specify important and relevant amounts, dates and locations inside the summary. Here is the dialog: $feature\\n\\nAssistant:\"\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb20053f-e76e-4ffc-b94d-a6589409776c",
   "metadata": {},
   "source": [
    "## Adding your own custom models\n",
    "In case you wish to add custom model, simply create custom model runner. For example, see custom model runner which wraps GPT-3.5 in the folder utils/model_runners/gpt_model_runner.py \n",
    "\n",
    "\n",
    "## Adding finetuned models\n",
    "In case you wish to add Bedrock finetuned model: \n",
    "1. First finetune a model (for details on finetuning on Berdrock visit https://aws.amazon.com/blogs/aws/customize-models-in-amazon-bedrock-with-your-own-data-using-fine-tuning-and-continued-pre-training/).\n",
    "2. Once training completed, from Bedrock copy the ARN from Bedrock 'provisioned throughput' dashboard and paste it as the model_id. A finetuning training set is provided. For more details see documentation\n",
    "3. Add to the model_dict in the cell above the configuration of your finetuned model as follows:\n",
    "\n",
    "<code>\n",
    "{\n",
    "    \"finetuned_amazon.titan-text-lite-v1\" : {\n",
    "    \"platform\":\"bedrock\",\n",
    "    \"model_id\": \"arn:aws:bedrock:us-east-1:333333333:provisioned-model/879asd6s75\",\n",
    "    \"output\": \"results[0].outputText\",\n",
    "    \"content_template\": {\"inputText\": $prompt, \"textGenerationConfig\":  {\"maxTokenCount\": 100, \"stopSequences\": [], \"temperature\": 1.0, \"topP\": 1.0}},\n",
    "    \"prompt_template\": \"YOUR PROMPT HERE\"\n",
    "    }\n",
    "}\n",
    "</code>\n",
    "\n",
    "\n",
    "## Adding Jumpstart models\n",
    "Example for evaluation Mistral-7B-Instruct from Jumpstart:\n",
    "1. Go to Jumpstart (press home button -> Jumpstart)\n",
    "2. Search in the bar for Mistral-7B-Instruct\n",
    "3. Click deploy from the model card (don't forget to close the endpoint once you done from SageMaker->inference endpoints)\n",
    "4. Add the following to the models list\n",
    "<code>\n",
    "{\n",
    "    \"platform\":\"jumpstart\",\n",
    "    \"model_id\": \"huggingface-llm-mistral-7b-instruct\",\n",
    "    \"endpoint_name\": \"jumpstart-dft-hf-llm-mistral-7b-instruct\",\n",
    "    \"model_version\": \"*\",\n",
    "    \"output\": \"[0].generated_text\",\n",
    "    \"content_template\":\"{\\\"inputs\\\": $prompt, \\\"parameters\\\": {\\\"do_sample\\\": false, \\\"max_new_tokens\\\": 100}}\",\n",
    "    \"prompt_template\": \"YOUR PROMPT HERE\"\n",
    "}\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac160609-dfb3-4eb5-bac0-753053f27184",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating ModelRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9466069-430a-4f71-80a2-c0c6e3b4e918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_models_to_eval():\n",
    "    if len(MODELS_TO_EVAL) == 0:\n",
    "        return list(models_dict.keys())\n",
    "    return MODELS_TO_EVAL\n",
    "\n",
    "models = dict()        \n",
    "for fm in get_models_to_eval():  \n",
    "    \n",
    "    data = models_dict[fm]\n",
    "    platform = data['platform']\n",
    "    \n",
    "    if platform == \"bedrock\":\n",
    "        runner = BedrockModelRunner(model_id=data[\"model_id\"], output=data[\"output\"], content_template=data[\"content_template\"].replace(\"'\",\"\\\"\"))\n",
    "    elif platform == \"jumpstart\":\n",
    "        runner = JumpStartModelRunner(endpoint_name=data[\"endpoint_name\"], model_id=data[\"model_id\"], model_version=data[\"model_version\"], output=data[\"output\"].replace(\"'\",\"\\\"\"), content_template=data[\"content_template\"].replace(\"'\",\"\\\"\"))\n",
    "    elif platform == \"openai\":\n",
    "        if OPENAI_API_KEY != \"\":\n",
    "            runner = GPTModelRunner(GPTModelConfig(model_id=data[\"model_id\"], api_key=data[\"api_key\"], temperature=data[\"temperature\"], top_p=data[\"top_p\"], max_tokens=data[\"max_tokens\"]))\n",
    "        else:\n",
    "            print(\"Cannot run GPT without an API key\")\n",
    "        \n",
    "    models[fm] = { \"model_runner\": runner, \"prompt_template\": data[\"prompt_template\"]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6198a20-9a87-4a16-af6d-35733f9845c7",
   "metadata": {},
   "source": [
    "## Evaluation run\n",
    "Evaluating METEOR, ROUGE, and BERTscore using FMEval library (https://github.com/aws/fmeval). This library is also used by Bedrock when finetuning or evaluating models.\n",
    "\n",
    "#### Note - if while running this cell you encounter the message - \"Error displaying widget: model not found\" in the evaluation phase...\", simply ignore it. It relates to the UI and does not effect the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ec118e5-b099-49af-998a-1cacf6a7664b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Starting model random evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/sagemaker-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/sagemaker-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/sagemaker-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53b36f142094247be6f22adcfdb53f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Read progress 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877890f2860f4961b51fd6cfa7fe0255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Read progress 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/arrow_block.py:148: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  return transform_pyarrow.concat(tables)\n",
      "2024-03-13 13:51:00,032\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Repartition]\n",
      "2024-03-13 13:51:00,033\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 13:51:00,033\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4ca327a8994e9ab3a0de77e66fc62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Repartition 1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc57ff46e0f40d5aa171e7f1f1e217a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split Repartition 2:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e66ef885fc45a9833d408b9b7ec8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 13:51:00,095\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(_generate_prompt_column)]\n",
      "2024-03-13 13:51:00,096\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 13:51:00,097\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20ff448186140b7addd5be5239938ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 13:51:00,143\tWARNING util.py:546 -- The argument ``compute`` is deprecated in Ray 2.9. Please specify argument ``concurrency`` instead. For more information, see https://docs.ray.io/en/master/data/transforming-data.html#stateful-transforms.\n",
      "2024-03-13 13:51:00,147\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> ActorPoolMapOperator[Map(ModelRunnerWrapper)]\n",
      "2024-03-13 13:51:00,148\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 13:51:00,149\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2024-03-13 13:51:00,168\tINFO actor_pool_map_operator.py:114 -- Map(ModelRunnerWrapper): Waiting for 1 pool actors to start...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5849fc65106347f584a11891dfc020eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 13:51:12,195\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(_generate_eval_scores)]\n",
      "2024-03-13 13:51:12,195\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 13:51:12,196\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60505e11a91b436f9de4b24e48c204b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 13:51:26,075\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-13 13:51:26,076\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 13:51:26,077\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8490b80afa68441ea1107fc4cc96044f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb5e036732e4bd0863e89a25cfa839a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e3fc8ae08344b98682bebf5d99d92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cba611ded524f3892a5098e6879149a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 13:51:26,140\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-13 13:51:26,141\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 13:51:26,142\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077b4650fb5b45e599891aa7f256d209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5db379419954bdeb73f411e94eb07eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77b52f3b68d458ba87489bef6660826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c2d2b0801448bcb35fa0c56b6356a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 13:51:26,202\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-13 13:51:26,203\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 13:51:26,204\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc6769475914f97bc80bf5f5e70641c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19aa2f9f8564b1e9ff808c212b2a403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f874cc608c44fbdb462b202491234c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b72611a0f143888e812a52265c3af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 13:51:26,264\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)]\n",
      "2024-03-13 13:51:26,264\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 13:51:26,265\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e4a15104be410fb716f1d695402a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 13:51:26,309\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)]\n",
      "2024-03-13 13:51:26,310\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 13:51:26,310\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0466f36fee3f407d82f68e50abd4ccf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "[nltk_data] Downloading package wordnet to /home/sagemaker-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/sagemaker-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/sagemaker-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Starting model anthropic.claude-instant-v1 evaluation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7076720280ec404b8232c79bbd5c3a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Read progress 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661105826ae54793ac60b1f2665f58b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Read progress 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/arrow_block.py:148: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  return transform_pyarrow.concat(tables)\n",
      "2024-03-13 13:51:26,470\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Repartition]\n",
      "2024-03-13 13:51:26,471\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 13:51:26,471\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c663f233397b460db013ed4bb754559c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Repartition 1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f8102d5ae64eeca832df3acf193057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split Repartition 2:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd7f843598d429b9b67e91c13ae0f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 13:51:26,562\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(_generate_prompt_column)]\n",
      "2024-03-13 13:51:26,562\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 13:51:26,563\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9cf933777649a0ad43d5e7e1685252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 13:51:26,616\tWARNING util.py:546 -- The argument ``compute`` is deprecated in Ray 2.9. Please specify argument ``concurrency`` instead. For more information, see https://docs.ray.io/en/master/data/transforming-data.html#stateful-transforms.\n",
      "2024-03-13 13:51:26,621\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> ActorPoolMapOperator[Map(ModelRunnerWrapper)]\n",
      "2024-03-13 13:51:26,622\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 13:51:26,623\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2024-03-13 13:51:26,645\tINFO actor_pool_map_operator.py:114 -- Map(ModelRunnerWrapper): Waiting for 1 pool actors to start...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628cc283167b4d97ba808e50fd9e0e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 13:51:48,228\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(_generate_eval_scores)]\n",
      "2024-03-13 13:51:48,228\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 13:51:48,229\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b5638d5f4b43b8ad47e8dc4ccac69b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 13:52:08,904\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-13 13:52:08,905\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 13:52:08,905\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ce6c0f7fe24f8ebdaecc2bdcd231cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8934d44a70944bcb49c54f63c37d829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ab21fa015d430bb62c853393634c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f03be678414106ad07cf76c7658a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 13:52:08,971\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-13 13:52:08,971\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 13:52:08,972\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd9316dd50d4573ae2cabc556746624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fe241275924d4c9f6a6c802d651a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e4f948fbea4571919984c92e2b9061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb67742a24aa48b099a4d70ec14a78aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 13:52:09,031\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-13 13:52:09,031\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 13:52:09,032\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f40b9f47b13428da89574ce1b322c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcea019c2c0141409c57f97c3354fdc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a233ebd0449476d95bb48e86c62826d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c0e5e6d1f24fe6b58be8d4db90841c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 13:52:09,092\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)]\n",
      "2024-03-13 13:52:09,093\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 13:52:09,094\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6489c393e6547329e021efb989c6e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 13:52:09,137\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)]\n",
      "2024-03-13 13:52:09,137\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 13:52:09,138\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c6023f1e3541338d86011b2b209819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/home/sagemaker-user/fm-leaderboarder/.venv/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n"
     ]
    }
   ],
   "source": [
    "from fmeval.data_loaders.data_config import DataConfig\n",
    "from fmeval.constants import MIME_TYPE_JSONLINES\n",
    "from fmeval.eval_algorithms.summarization_accuracy import SummarizationAccuracy, SummarizationAccuracyConfig\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "models_scores = dict()\n",
    "for model_id in get_models_to_eval():\n",
    "    print(f\"### Starting model {model_id} evaluation\")\n",
    "    model = models[model_id]\n",
    "    config = DataConfig(\n",
    "        dataset_name=f\"data\",\n",
    "        dataset_uri=TEST_FILE_PATH,\n",
    "        dataset_mime_type=MIME_TYPE_JSONLINES,\n",
    "        model_input_location=\"document\",\n",
    "        target_output_location=\"summary\"\n",
    "    )\n",
    "\n",
    "    model_runner = model['model_runner']\n",
    "    eval_algo = SummarizationAccuracy(SummarizationAccuracyConfig())\n",
    "    eval_output = eval_algo.evaluate(model=model_runner, \n",
    "                                     dataset_config=config,\n",
    "                                     prompt_template=model[\"prompt_template\"],\n",
    "                                     num_records=10,\n",
    "                                     save=True)\n",
    "\n",
    "    scores = dict()\n",
    "    for i in eval_output[0].dataset_scores:\n",
    "        scores[i.name] = i.value\n",
    "    \n",
    "    models_scores[model_id] = scores\n",
    "\n",
    "    shutil.move('/tmp/eval_results/summarization_accuracy_data.jsonl', f'{TMP_JSON_FILES}/{model_id}_metrics.jsonl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf0a7ea-0ae1-423a-949a-6526b5b97ef9",
   "metadata": {},
   "source": [
    "## Calculate BARTscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e019170-e364-4c54-a030-b00207bcc5e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating random model\n",
      "Processed 10/10 samples.\n",
      "Evaluating anthropic.claude-instant-v1 model\n",
      "Processed 10/10 samples.\n"
     ]
    }
   ],
   "source": [
    "if CALC_BARTSCORE:\n",
    "    calculate_bartscore(TMP_JSON_FILES, models_scores, PATH_TO_FINETUNED_BART)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604b4580-546c-48ca-be94-fffabd1cc280",
   "metadata": {},
   "source": [
    "## Construct response HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c6485fe-e5b4-41b1-8323-470b963c8c20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated /tmp/final_result/index.html\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_response_output_view(RESULT_HTML_FOLDER, TMP_JSON_FILES, models_scores)\n",
    "create_comparive_dashboard(RESULT_HTML_FOLDER, TMP_JSON_FILES)\n",
    "create_data_stats_view(TEST_FILE_PATH, RESULT_IMG_FOLDER)\n",
    "create_data_preview_view(TEST_FILE_PATH, RESULT_HTML_FOLDER)\n",
    "main_html_filename = create_main_html(RESULT_FOLDER, models_scores)\n",
    "print(f\"Generated {main_html_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36570a56-4ba5-4143-aac0-b4ba99afce65",
   "metadata": {},
   "source": [
    "## Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75e36a98-6c1d-49ed-8f43-e2992be1e96d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To view the results on your local computer copy-paste these commands:\n",
      "    aws s3 cp s3://gili-dev/test_samples_result_13-03-2024_13-52-16.zip /tmp/test_samples_result_13-03-2024_13-52-16.zip\n",
      "    cd /tmp\n",
      "    unzip -d test_samples_result_13-03-2024_13-52-16 test_samples_result_13-03-2024_13-52-16.zip\n",
      "    open /tmp/test_samples_result_13-03-2024_13-52-16/index.html\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "today = datetime.now()\n",
    "\n",
    "d1 = today.strftime(\"%d-%m-%Y_%H-%M-%S\") # dd/mm/YY\n",
    "shutil.make_archive(f\"/tmp/{str(d1)}\", 'zip', \"/tmp/final_result\")\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3_key = f\"{OUTPUT_FILENAME}_{str(d1)}.zip\"\n",
    "s3.meta.client.upload_file(f\"/tmp/{str(d1)}.zip\", OUTPUT_BUCKET, s3_key)\n",
    "print(f'To view the results on your local computer copy-paste these commands:\\n\\\n",
    "    aws s3 cp s3://{OUTPUT_BUCKET}/{s3_key} /tmp/{s3_key}\\n\\\n",
    "    cd /tmp\\n\\\n",
    "    unzip -d {s3_key.replace(\".zip\",\"\")} {s3_key}\\n\\\n",
    "    open /tmp/{s3_key.replace(\".zip\",\"\")}/index.html')"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
